# 项目文档：Seenomaly: Vision-Based Linting of GUI Animation  Effects Against Design-Don’t Guidelines

> 基于视觉的GUI动画效果检查
>
> 191250128 孙钰昇

[TOC]



# 论文阅读

像卡片移动、菜单滑进划出、SnackBar（一种安卓菜单）显示等动画都**不应该违反平台的UI设计准则**，包括组件的运动和交互、内容的出现和消失以及高度和阴影的变化，都是现有的静态程序分析、功能性GUI规范测试和图像对比技术不能实现分析的。

文章将图形用户界面动画的分类公式化为一个多类的屏幕录像分类任务，提出了一个无监督的基于计算机视觉的对抗自编码器（VAE、GAN）。通过自编码器来“看到”大量未标记的真实应用GUI动画并学习生成类似的动画分组。

## 工具思想

由于GUI设计指南是简洁的，是少数的图形用户动画示例，并不足以支持大量数据标注的监督式学习方法。因此只能使用无监督学习技术。

使用自动GUI探索方法构建大型的未标记GUI动画数据集。然后利用这个数据集，训练基于视觉的GUI动画特征提取器，学习以无监督的方式提取GUI动画的重要时空特征。接下来，使用训练好的特征提取器将一些典型的违反设计准则的GUI动画映射到一个密集的向量空间中。一个需要嵌入的GUI动画也被映射到这个空间，然后使用KNN算法确定它是否违规。

## 工具分解

### GUI动画屏幕录像处理

工具接受三种形式的输入，一种是线性的GUI动画屏幕录像。第二种是一部分GUI动画屏幕截图。第二种是设计准则的标签数据，可以从设计文档、应用程序、相关讨论区收集。第三种是从真实应用中获得的大量GUI动画屏幕录像。

对于输入的动画，以每秒5个截图频率记录GUI屏幕。这种方式的好处是能够记录GUI动画的显著变化而不需要记录屏幕变化之间的许多静态帧。当用户和程序交互，并产生显著的屏幕变化后，记录开始。当下一个用户操作开始或屏幕保持静态1秒以上时，记录停止。

### GUI动画特征提取

- 模型架构：自动编码器VAE、生成对抗网络GAN
- 核心思想：通过学习生成GUI动画屏幕投影来推断潜在的时空特征表示，并将真实的GUI动画屏幕投影与生成的图形区分开来。
- 组成：学习重建输入GUI动画录像的VAE、通过对抗增强VAE生成能力的GAN、从重建屏幕录像中学习更抽象特征表示的额外特征编码器网络。

VAE、 GAN和特征编码器网络使用未标记的 GUI 动画屏幕录像进行联合培训，培训由不同网络中的三个损失函数指导，目的是尽量缩小输入屏幕录像和生成屏幕录像之间的距离，以及这些屏幕录像的潜在特征向量之间的距离。这些损耗函数是VAE网络的重构损耗Lrec，GAN网络的对抗损耗Ladv，以及额外特征编码器的编码器损耗Lenc。这三个损失函数组合在一起作为模型损失 = Lrec + Ladv +  Lenc 以共同优化网络。

在推理时，使用 VAE 编码器和附加特征编码器分别获得输入的 z  值和重构的 GUI 动画屏幕录像的 z 值，然后将输入屏幕录像连接到 潜在特征空间。在这个空间中，GUI 动画的相似性可以由它们的特征 向量的 l2 距离来决定。

#### 特征编码器

使用三维卷积神经网络从屏幕录像中提取时空特征。具有k*k空间大小和d时间深度的三维卷积核在三个方向 (高度、宽度和深度)的一系列帧上滑动。3D-CNN 已经成功地用于动作识别任务

#### VAE

由编码器子网络vAEE和解码器子网络vAED组成。学习目标是最小化输入 x 和重构输入 x 之间的差 异。在这项工作中，我们计算 x 和 x 之间的 l1 距离作为VAE 网络的损失函数(称为重构损失) :

![](C:\Users\rubisco\Desktop\大三笔记\自动化测试\作业\工具实现\pics\QQ截图20211123202518.png)

其中 f i 和 f i 分别是 x 和 x 中的第 1 个截图。通过最小化重构损失，潜在矢量 z 可以捕获输入 x 的最重要的时空特征， 使得重构的输入 x 具有最小的信息损失。

#### GAN

一个 GAN 由一对网络组成: 一个发生器 g 试图从数据分布中生成样本，一个鉴别器 d 试图区分真实样本和生 成的假样本。该网络在极小-极大博弈中训练，其中生成器寻求最大限度地欺骗鉴别器，同时鉴别器寻求确定样本有效性(即真假) ，两个网络最终达到纳什均衡点。





在模型中，VAE 解码器扮演着生成器 g 的角色。鉴别器 d  类似于深度卷积生成对抗网络(DCGAN)中的鉴别器网络，但是我们的 模型使用三维而不是二维卷积层。这个鉴别器是一个二进制分类器， 用于预测真实或虚假输入。在我们的工作中，真实输入是 x，假输入 是 x。在对抗训练设置中，生成器根据鉴别器的分类输出进行更新。 二进制分类器输出: Ladv = log d (x) + log (1-d (x))的交叉熵损失是分辨率损失(称为对抗性损失)。

### 基于KNN搜索的GUI动画测试

使用VAE编码器和额外的特征编码器来映射关联GUI动画和GUI动画示例的设计指南到一个低维的潜在特征空间。然后，找到top-k GUI动画实例——这些实例与特征空间中的线性GUI动画非常接近。这两个GUI动画的距离是由它们的特征向量 v1 和 v2 的 l2 距离计算出来的，也就是∥ v1-v2∥2。使用 k 最接近的 GUI 动画示例的多数票来确定线性 GUI 动画违反的准则。 如果大多数投票结果为平局，比较平局准则中 GUI 动画示例的平均距离，并将平均距离最短的准则作为线性 GUI 动画违反的准则。

# 工具实现

## 输入处理

### 录像处理

在datasets中的spilt_video.py完成了一部分功能。它检查目标目录下的所有输入录像，对每个录像都比对出最多任意设定数目的操作截图（超过数目的采用随机选取），存在同名文件夹中。并得出一个label文件。

### 图片处理

- 采用RI_CO数据集，利用其标注的json文件，在get_data.py中实现对GIF的截取和清除静态图片。并生成一个class_name文件。其中，利用json文件的信息得到全部的图片。然后判断图片之间的相似度。如果相似度不大，就加入“不同图片”列表。最后将这些不同图片输出出来。
- 在get_class.py中读取所有的class_name，并生成一个label



最后通过convert_data_to_tfrecord.py，将label和图片转换为TensorFlow中用于训练的记录文件tfRecord

## 动画特征处理

使用tensorflow在项目中实现了VAE、GAN、VAEGAN、FBN、AERNN、C3D等神经网络模型

### VAE

- 自动编码机Auto-Encoder (AE)由两部分encoder和decoder组成，encoder输入x数据，输出潜在变量z，decoder输入z然后输出一个x’，目的是让x’与x的分布尽量一致，当两者完全一样时，中间的潜在变量z可以看作是x的一种压缩状态，包含了x的全部feature特征，此时监督信号就是原数据x本身。
- 变分自动编码机VAE是自动编码机的一种扩展，它假设输出的潜在变量z服从一种先验分布，如高斯分布。这样，在训练完模型后，我们可以通过采样这种先验分布得到z’，这个z’可能是训练过程中没有出现过的，但是我们依然能在解码器中通过这个z’获得x’，从而得到一些符合原数据x分布的新样本，具有“生成“新样本的能力。

在实现方面采用TensorFlow-Slim，这是一种是用于定义、训练和评估复杂模型的tensorflow轻量级库。tf-slim的组件能轻易地与原生tensorflow框架还有其他的框架（例如tf.contrib.learn）进行整合。

- 编码器
  - 利用slim对输入进行多次3D卷积池化，具体实现可以结合代码注释查看
- 解码器
  - 对编码器的结果进行反卷积

### GAN

GAN主要由两部分构成：generator和discriminator，generator主要是从训练数据中产生相同分布的samples，而discriminator 则是判断输入是真实数据还是generator生成的数据，discriminator采用传统的监督学习的方法。

具体实现方面，依然采用slim实现，可参见

- 生成模型
  - 利用vae生成模型
- 对抗模型
  - 一个神经网络模型，对数据进行多次卷积

## 模型评估

### 摘录特征

首先加载最新训练好的模型，然后从图片数据集中匹配图片默认大小，添加图片。加载预训练模型。并提取特征，经过PCA降维后保存在feature.p中。

### 测试

首先加载上一步中提取到的特征，然后将特征和label作为x和y，分成训练集和测试集。最后调用K-NN算法检测算法的准确性，结果保存在result中。

# 实验结果

经检验，在本机实地运行的准确度基本达到论文中效果。

![](.\pics\QQ截图20211125171145.png)

